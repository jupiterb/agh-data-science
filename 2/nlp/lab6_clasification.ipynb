{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# colab or locally?\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    \n",
    "    drive.mount(\"/content/drive/\")\n",
    "\n",
    "    resources_dir = \"/content/drive/MyDrive/projects/nlp\"\n",
    "\n",
    "    data_dir = f\"{resources_dir}/data\"\n",
    "    models_dir = f\"{resources_dir}/models\"\n",
    "\n",
    "    packages = [\"sacremoses\", \"datasets\", \"evaluate\", \"transformers[torch]\"]\n",
    "\n",
    "    import subprocess\n",
    "    import sys\n",
    "\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "except:\n",
    "    data_dir = f\"./data\"\n",
    "    models_dir = f\"./models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1-3\n",
    "Create a dataset of positive and negative sentence pairs.\n",
    "The dataset should be split into training, evaluation and testing subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Nie mówię, że nie podoba mi się też pomysł szk...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>Tak więc nic nie zapobiega fałszywym ocenom po...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td></td>\n",
       "      <td>Nigdy nie możesz korzystać z FSA dla indywidua...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td></td>\n",
       "      <td>Samsung stworzył LCD i inne technologie płaski...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td></td>\n",
       "      <td>Oto wymagania SEC: Federalne przepisy dotycząc...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title                                               text metadata\n",
       "_id                                                                  \n",
       "3          Nie mówię, że nie podoba mi się też pomysł szk...       {}\n",
       "31         Tak więc nic nie zapobiega fałszywym ocenom po...       {}\n",
       "56         Nigdy nie możesz korzystać z FSA dla indywidua...       {}\n",
       "59         Samsung stworzył LCD i inne technologie płaski...       {}\n",
       "63         Oto wymagania SEC: Federalne przepisy dotycząc...       {}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = pd.read_json(f\"{data_dir}/corpus.jsonl\", lines=True)\n",
    "corpus_df = corpus_df.set_index(\"_id\").sort_index()\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zgłaszanie wydatków biznesowych dla firmy bez ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Przekazywanie pieniędzy z jednej kontroli bizn...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Posiadanie oddzielnego konta bankowego do prow...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text metadata\n",
       "_id                                                            \n",
       "0    Co jest uważane za wydatek służbowy w podróży ...       {}\n",
       "1    Zgłaszanie wydatków biznesowych dla firmy bez ...       {}\n",
       "2    Przekazywanie pieniędzy z jednej kontroli bizn...       {}\n",
       "3    Posiadanie oddzielnego konta bankowego do prow...       {}\n",
       "4    Wydatki służbowe - ubezpieczenie samochodu pod...       {}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df = pd.read_json(f\"{data_dir}/queries.jsonl\", lines=True)\n",
    "queries_df = queries_df.set_index(\"_id\").sort_index()\n",
    "queries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all train positive examples: 14166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>196463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>69306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>560251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>188530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id  corpus-id  score\n",
       "0         0      18850      1\n",
       "1         4     196463      1\n",
       "2         5      69306      1\n",
       "3         6     560251      1\n",
       "4         6     188530      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_train_all_df = pd.read_csv(f\"{data_dir}/train.tsv\", sep=\"\\t\")\n",
    "print(f\"Number of all train positive examples: {len(qa_train_all_df)}\")\n",
    "\n",
    "qa_train_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test positive examples: 1706\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>566392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>65404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>325273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>88124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>285255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id  corpus-id  score\n",
       "0         8     566392      1\n",
       "1         8      65404      1\n",
       "2        15     325273      1\n",
       "3        18      88124      1\n",
       "4        26     285255      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_test_df = pd.read_csv(f\"{data_dir}/test.tsv\", sep=\"\\t\")\n",
    "print(f\"Number of test positive examples: {len(qa_test_df)}\")\n",
    "\n",
    "qa_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train positive examples: 11332\n",
      "Number of validation positive examples: 2834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "qa_train_df, qa_validation_df = train_test_split(\n",
    "    qa_train_all_df, test_size=0.2, random_state=3242\n",
    ")\n",
    "\n",
    "print(f\"Number of train positive examples: {len(qa_train_df)}\")\n",
    "print(f\"Number of validation positive examples: {len(qa_validation_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ids = set([row[\"corpus-id\"] for _, row in qa_train_df.iterrows()])\n",
    "validation_doc_ids = set([row[\"corpus-id\"] for _, row in qa_validation_df.iterrows()])\n",
    "test_doc_ids = set([row[\"corpus-id\"] for _, row in qa_test_df.iterrows()])\n",
    "\n",
    "train_corpus_df = corpus_df.loc[list(train_doc_ids)]\n",
    "validation_corpus_df = corpus_df.loc[list(validation_doc_ids)]\n",
    "test_corpus_df = corpus_df.loc[list(test_doc_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class SearchEngine(ABC):\n",
    "    @abstractmethod\n",
    "    def get_top_searches(self, query: str, limit: int) -> pd.DataFrame:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "\n",
    "class ESSearchEngine(SearchEngine):\n",
    "    def __init__(self, index_name: str, corpus: pd.DataFrame) -> None:\n",
    "        \"\"\"corpus should contain column 'text' with documents.\"\"\"\n",
    "        self._es = Elasticsearch(\n",
    "            \"https://localhost:9200\",\n",
    "            basic_auth=(\"elastic\", \"Ay+zsdo6Y02ThQs7SCFM\"),\n",
    "            ca_certs=\"./elasticsearch/http_ca.crt\",\n",
    "        )\n",
    "        self._index_name = index_name\n",
    "        self._create_index()\n",
    "        self._load_data(corpus)\n",
    "\n",
    "    def _create_index(self) -> None:\n",
    "        index_settings = {\n",
    "            \"settings\": {\n",
    "                \"analysis\": {\n",
    "                    \"analyzer\": {\n",
    "                        \"analyze_lemma\": {\n",
    "                            \"tokenizer\": \"standard\",\n",
    "                            \"filter\": [\n",
    "                                \"lowercase\",\n",
    "                                \"morfologik_stem\", \n",
    "                                \"lowercase\",\n",
    "                            ]\n",
    "                        },\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"analyze_lemma\",\n",
    "                    },\n",
    "                    \"id\": {\n",
    "                        \"type\": \"text\",\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            self._es.indices.delete(index=self._index_name)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self._es.indices.create(index=self._index_name, body=index_settings) # type: ignore\n",
    "\n",
    "    def _load_data(self, corpus: pd.DataFrame) -> None:\n",
    "        docs = []\n",
    "\n",
    "        for id, row in corpus.iterrows():\n",
    "            item = {\n",
    "                \"_index\": self._index_name,\n",
    "                \"_source\": {\n",
    "                    \"text\": row[\"text\"],\n",
    "                    \"id\": id,\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            docs.append(item)\n",
    "\n",
    "        helpers.bulk(self._es, docs)\n",
    "\n",
    "    def get_top_searches(self, query: str, limit: int) -> pd.DataFrame:\n",
    "        query_body = {\n",
    "            \"size\": limit,\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"text\": query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = self._es.search(index=self._index_name, body=query_body) # type: ignore\n",
    "\n",
    "        ids = [item[\"_source\"][\"id\"] for item in response[\"hits\"][\"hits\"]]\n",
    "        docs = [item[\"_source\"][\"text\"] for item in response[\"hits\"][\"hits\"]]\n",
    "\n",
    "        return pd.DataFrame({\"id\": ids, \"text\": docs}).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/06zrhgts1xlbpl77yjk6_83m0000gn/T/ipykernel_72153/2195271707.py:50: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  self._es.indices.create(index=self._index_name, body=index_settings) # type: ignore\n"
     ]
    }
   ],
   "source": [
    "es_train_search_engine = ESSearchEngine(\"train\", train_corpus_df)\n",
    "es_validation_search_engine = ESSearchEngine(\"validation\", validation_corpus_df)\n",
    "es_test_search_engine = ESSearchEngine(\"test\", test_corpus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Jak zdeponować czek wystawiony na współpracownika w mojej firmie na moje konto firmowe?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/06zrhgts1xlbpl77yjk6_83m0000gn/T/ipykernel_72153/2195271707.py:78: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = self._es.search(index=self._index_name, body=query_body) # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176017</th>\n",
       "      <td>„Czeki (w każdym razie w USA) są ważne tylko p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316359</th>\n",
       "      <td>Z mojego doświadczenia wynika, że ​​nie musisz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580624</th>\n",
       "      <td>Bank nie pozwoli Ci na to, ponieważ: Różnice w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445739</th>\n",
       "      <td>„Jak/kiedy mój pracodawca dowiaduje się o tym?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28974</th>\n",
       "      <td>„Zgadzam się z resztą odpowiedzi – prawdopodob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108734</th>\n",
       "      <td>„Mamy lokalny bank, który przeszedł na usługę ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165397</th>\n",
       "      <td>„Najlepszym powodem poparcia czeku jest jego z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334902</th>\n",
       "      <td>Nie ma powodu, aby otwierać firmę. Pomoże Ci j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456636</th>\n",
       "      <td>Rachunek bieżący oferuje wiele korzyści dla os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271116</th>\n",
       "      <td>Absolutne oszustwo. Za każdym razem, gdy ktoś ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "id                                                       \n",
       "176017  „Czeki (w każdym razie w USA) są ważne tylko p...\n",
       "316359  Z mojego doświadczenia wynika, że ​​nie musisz...\n",
       "580624  Bank nie pozwoli Ci na to, ponieważ: Różnice w...\n",
       "445739  „Jak/kiedy mój pracodawca dowiaduje się o tym?...\n",
       "28974   „Zgadzam się z resztą odpowiedzi – prawdopodob...\n",
       "108734  „Mamy lokalny bank, który przeszedł na usługę ...\n",
       "165397  „Najlepszym powodem poparcia czeku jest jego z...\n",
       "334902  Nie ma powodu, aby otwierać firmę. Pomoże Ci j...\n",
       "456636  Rachunek bieżący oferuje wiele korzyści dla os...\n",
       "271116  Absolutne oszustwo. Za każdym razem, gdy ktoś ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_query = queries_df.iloc[8][\"text\"]\n",
    "\n",
    "print(f\"Query: {_query}\")\n",
    "\n",
    "es_train_search_engine.get_top_searches(_query, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive and negative pairs using ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_query_and_doc(query: str, doc: str) -> str:\n",
    "    return f\"Pytanie: {query} Odpowiedź: {doc}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "\n",
    "\n",
    "def _queries_to_docs_map(qa: pd.DataFrame) -> dict[int, list[int]]:\n",
    "    qa_map = {}\n",
    "\n",
    "    for _, (query_id, doc_id, _) in qa.iterrows():\n",
    "        if query_id in qa_map:\n",
    "            qa_map[query_id].append(doc_id)\n",
    "        else:\n",
    "            qa_map[query_id] = [doc_id]\n",
    "\n",
    "    return qa_map\n",
    "\n",
    "\n",
    "def _query_df(\n",
    "        search_engine: SearchEngine,\n",
    "        query: str, \n",
    "        positive_ids: list[int],\n",
    "        docs: pd.DataFrame, \n",
    "        negative_candidates_factor: int,\n",
    "        negative_examples_factor: int,\n",
    "    ) -> pd.DataFrame:\n",
    "        num_positive = len(positive_ids)\n",
    "\n",
    "        candidates_ids = search_engine.get_top_searches(\n",
    "            query, \n",
    "            (negative_candidates_factor * negative_examples_factor) + num_positive\n",
    "        ).index\n",
    "\n",
    "        negative_candidates_ids = list(candidates_ids.difference(positive_ids))\n",
    "        \n",
    "        negative_ids = choices(\n",
    "            negative_candidates_ids, k=negative_examples_factor * num_positive\n",
    "        )\n",
    "\n",
    "        examples = {}\n",
    "\n",
    "        examples[\"text\"] = [ \n",
    "            merge_query_and_doc(query, docs.loc[id][\"text\"])\n",
    "            for id in positive_ids + negative_ids\n",
    "        ]\n",
    "        examples[\"label\"] = [1 for _ in positive_ids] + [0 for _ in negative_ids]\n",
    "\n",
    "        return pd.DataFrame(examples)\n",
    "\n",
    "\n",
    "def qa_pairs_df(\n",
    "    search_engine: SearchEngine,\n",
    "    queries: pd.DataFrame, \n",
    "    docs: pd.DataFrame, \n",
    "    positive_qa: pd.DataFrame, \n",
    "    negative_candidates_factor: int = 80,\n",
    "    negative_examples_factor: int = 8,\n",
    ") -> pd.DataFrame:\n",
    "    qa_map = _queries_to_docs_map(positive_qa)\n",
    "\n",
    "    examples = [\n",
    "        _query_df(\n",
    "            search_engine,\n",
    "            queries.loc[query_id][\"text\"], \n",
    "            positive_ids,\n",
    "            docs, \n",
    "            negative_candidates_factor,\n",
    "            negative_examples_factor,\n",
    "        ) \n",
    "        for query_id, positive_ids in qa_map.items()\n",
    "    ]\n",
    "\n",
    "    pairs = pd.concat(examples, ignore_index=True)    \n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/06zrhgts1xlbpl77yjk6_83m0000gn/T/ipykernel_72153/2195271707.py:78: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = self._es.search(index=self._index_name, body=query_body) # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 101988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pytanie: Dlaczego warto pożyczyć pieniądze na ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pytanie: Dlaczego warto pożyczyć pieniądze na ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pytanie: Dlaczego warto pożyczyć pieniądze na ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pytanie: Dlaczego warto pożyczyć pieniądze na ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pytanie: Dlaczego warto pożyczyć pieniądze na ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Pytanie: Dlaczego warto pożyczyć pieniądze na ...      1\n",
       "1  Pytanie: Dlaczego warto pożyczyć pieniądze na ...      1\n",
       "2  Pytanie: Dlaczego warto pożyczyć pieniądze na ...      1\n",
       "3  Pytanie: Dlaczego warto pożyczyć pieniądze na ...      0\n",
       "4  Pytanie: Dlaczego warto pożyczyć pieniądze na ...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs_df = qa_pairs_df(es_train_search_engine, queries_df, corpus_df, qa_train_df)\n",
    "validation_pairs_df = qa_pairs_df(es_validation_search_engine, queries_df, corpus_df, qa_validation_df)\n",
    "test_pairs_df = qa_pairs_df(es_test_search_engine, queries_df, corpus_df, qa_test_df)\n",
    "\n",
    "print(f\"Number of train examples: {len(train_pairs_df)}\")\n",
    "train_pairs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4-5\n",
    "Train a text classifier using the Transformers library that distinguishes between the positive and the negative pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrbialy/Projects/agh-data-science/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "model_name = \"allegro/herbert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "\n",
    "datasets_dir = f\"{data_dir}/qa_classification\"\n",
    "\n",
    "\n",
    "def _load_datasets() -> DatasetDict:\n",
    "    return DatasetDict({\n",
    "        \"train\": load_from_disk(f\"{datasets_dir}/train\"),\n",
    "        \"validation\": load_from_disk(f\"{datasets_dir}/validation\"),\n",
    "        \"test\": load_from_disk(f\"{datasets_dir}/test\"),\n",
    "    })\n",
    "\n",
    "\n",
    "def _create_datasets() -> DatasetDict:\n",
    "    datasets = DatasetDict({\n",
    "        \"train\": Dataset.from_pandas(train_pairs_df),\n",
    "        \"validation\": Dataset.from_pandas(validation_pairs_df),\n",
    "        \"test\": Dataset.from_pandas(test_pairs_df),\n",
    "    })\n",
    "    datasets = datasets.map(tokenize_function, batched=True)\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def get_datasets() -> DatasetDict:\n",
    "    try:\n",
    "        return _load_datasets()\n",
    "    except:\n",
    "        datasets =  _create_datasets()\n",
    "        datasets.save_to_disk(datasets_dir)\n",
    "        return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 101988/101988 [00:24<00:00, 4142.33 examples/s]\n",
      "Map: 100%|██████████| 25506/25506 [00:05<00:00, 4584.79 examples/s]\n",
      "Map: 100%|██████████| 15354/15354 [00:03<00:00, 4516.63 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 101988/101988 [00:00<00:00, 1066643.09 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 25506/25506 [00:00<00:00, 1097072.40 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 15354/15354 [00:00<00:00, 997727.88 examples/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 101988\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = get_datasets()\n",
    "datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "model_name = \"allegro/herbert-base-cased\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in list(model.base_model.parameters())[:165]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name}, Requires gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "\n",
    "arguments = TrainingArguments(\n",
    "    output_dir=f\"{models_dir}/qa_classifier/output\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1500,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-05,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=1e-3,\n",
    "    num_train_epochs=4,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1500,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer, padding=\"longest\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=datasets[\"train\"].shuffle(seed=4664), # type: ignore\n",
    "    eval_dataset=datasets[\"validation\"].shuffle(seed=4664), # type: ignore\n",
    "    compute_metrics=compute_metrics, # type: ignore\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training report\n",
    "| Step  | Training Loss | Validation Loss | F1       |\n",
    "|-------|---------------|-----------------|----------|\n",
    "| 1500  | 0.266200      | 0.262476        | 0.479271 |\n",
    "| 3000  | 0.264700      | 0.221167        | 0.438429 |\n",
    "| 4500  | 0.239600      | 0.202747        | 0.554478 |\n",
    "| 6000  | 0.237600      | 0.210558        | 0.511858 |\n",
    "| 7500  | 0.254500      | 0.197017        | 0.567064 |\n",
    "| 9000  | 0.213700      | 0.190644        | 0.623537 |\n",
    "| 10500 | 0.215900      | 0.205007        | 0.542047 |\n",
    "| 12000 | 0.229500      | 0.196024        | 0.566897 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6-7\n",
    "Use the classifier as a re-ranker for finding the answers to the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "source": [
    "from torch import no_grad, backends, device\n",
    "\n",
    "\n",
    "if backends.mps.is_available():\n",
    "    current_device = device(\"mps\")\n",
    "else:\n",
    "    current_device = device(\"cpu\")\n",
    "    \n",
    "print(f\"Device is {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "class ClassifierSupportedSearchEngine(SearchEngine):\n",
    "    def __init__(\n",
    "        self, \n",
    "        search_engine: SearchEngine, \n",
    "        classifier: BertForSequenceClassification,\n",
    "        tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast,\n",
    "        num_candidates: int = 30,\n",
    "    ) -> None:\n",
    "        self._wrapped_engine = search_engine\n",
    "        self._classifier = classifier\n",
    "        self._tokenizer = tokenizer\n",
    "        self._num_candidates = num_candidates\n",
    "\n",
    "    def get_top_searches(self, query: str, limit: int) -> pd.DataFrame:\n",
    "        results = self._wrapped_engine.get_top_searches(\n",
    "            query, max(self._num_candidates, limit)\n",
    "        )\n",
    "        re_ranked_results = self._re_rank(query, results)\n",
    "        return re_ranked_results.head(limit)\n",
    "    \n",
    "    def _re_rank(self, query: str, results: pd.DataFrame) -> pd.DataFrame:\n",
    "        data = []\n",
    "        scores = {}\n",
    "        texts = []\n",
    "\n",
    "        for id, row in results.iterrows():\n",
    "            doc = row[\"text\"] \n",
    "            data.append({\"id\": id, \"text\": doc})\n",
    "            text = merge_query_and_doc(query, doc)\n",
    "            texts.append(text)\n",
    "            \n",
    "        tokens = self._tokenizer(\n",
    "            texts, \n",
    "            max_length=512, \n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(current_device)\n",
    "\n",
    "        with no_grad():\n",
    "            outputs = self._classifier(**tokens)\n",
    "\n",
    "        for id, score in zip(results.index, outputs.logits):\n",
    "            scores[id] = score[1].item()\n",
    "\n",
    "        data = sorted(data, key=lambda item: scores[item[\"id\"]], reverse=True)\n",
    "\n",
    "        return pd.DataFrame(data).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "path_to_best = f\"{models_dir}/qa_classifier/output/checkpoint-9000\"\n",
    "\n",
    "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    path_to_best, num_labels=2\n",
    ").to(current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_search_engine = ClassifierSupportedSearchEngine(\n",
    "    es_test_search_engine, fine_tuned_model, tokenizer, num_candidates=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Jak zdeponować czek wystawiony na współpracownika w mojej firmie na moje konto firmowe?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/06zrhgts1xlbpl77yjk6_83m0000gn/T/ipykernel_72153/2195271707.py:78: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = self._es.search(index=self._index_name, body=query_body) # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65404</th>\n",
       "      <td>Po prostu poproś współpracownika o podpisanie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590102</th>\n",
       "      <td>Kiedy firma prosi mnie o wystawienie czeku na ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508754</th>\n",
       "      <td>„Sprawdziłem w Bank of America i mówią, że JED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566392</th>\n",
       "      <td>Poproś o ponowne wystawienie czeku właściwemu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220691</th>\n",
       "      <td>W Wielkiej Brytanii oficjalną zasadą jest to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89326</th>\n",
       "      <td>Czeki są zwykle numerowane sekwencyjnie, aby z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555486</th>\n",
       "      <td>„1.Dlaczego nie ma adnotacji „„Skarbu Stanów Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342212</th>\n",
       "      <td>Byłem właścicielem, a także najemcą. Mogłem wp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213331</th>\n",
       "      <td>„Twój przyjaciel prawdopodobnie nie może wpłac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29372</th>\n",
       "      <td>„Powiedzmy, że jesteś mi winien 123,00 USD i c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "id                                                       \n",
       "65404   Po prostu poproś współpracownika o podpisanie ...\n",
       "590102  Kiedy firma prosi mnie o wystawienie czeku na ...\n",
       "508754  „Sprawdziłem w Bank of America i mówią, że JED...\n",
       "566392  Poproś o ponowne wystawienie czeku właściwemu ...\n",
       "220691  W Wielkiej Brytanii oficjalną zasadą jest to, ...\n",
       "89326   Czeki są zwykle numerowane sekwencyjnie, aby z...\n",
       "555486  „1.Dlaczego nie ma adnotacji „„Skarbu Stanów Z...\n",
       "342212  Byłem właścicielem, a także najemcą. Mogłem wp...\n",
       "213331  „Twój przyjaciel prawdopodobnie nie może wpłac...\n",
       "29372   „Powiedzmy, że jesteś mi winien 123,00 USD i c..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Query: {_query}\")\n",
    "\n",
    "classifier_search_engine.get_top_searches(_query, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8\n",
    "Compute how much the result of searching the passages improved over only FTS method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDCGBenchmark:\n",
    "    def __init__(\n",
    "        self, \n",
    "        queries: pd.DataFrame, \n",
    "        positive_qa: pd.DataFrame, \n",
    "    ) -> None:\n",
    "        self._queries = queries\n",
    "        self._scores_map = {}\n",
    "        \n",
    "        for _, row in positive_qa.iterrows():\n",
    "            query_id = row[\"query-id\"]\n",
    "            doc_id = row[\"corpus-id\"]\n",
    "            \n",
    "            if query_id not in self._scores_map:\n",
    "                self._scores_map[query_id] = dict()\n",
    "\n",
    "            self._scores_map[query_id][doc_id] = 1\n",
    "\n",
    "    def _eval_search_results(self, query_id: int, search_engine: SearchEngine, N: int) -> list[int]:\n",
    "        query = self._queries.loc[query_id][\"text\"]\n",
    "        results = search_engine.get_top_searches(query, N)\n",
    "        return [self._scores_map[query_id].get(corpus_id, 0) for corpus_id in results.index]\n",
    "    \n",
    "    def _eval_queries(self, search_engine: SearchEngine, N: int) -> np.ndarray:\n",
    "        num_queries = len(self._scores_map)\n",
    "        scores = np.empty((num_queries, N), dtype=int)\n",
    "\n",
    "        for i, query_id in enumerate(self._scores_map):\n",
    "            scores[i] = self._eval_search_results(query_id, search_engine, N)\n",
    "\n",
    "        return scores\n",
    "    \n",
    "    def _target_scores(self, N: int) -> np.ndarray:\n",
    "        num_queries = len(self._scores_map)\n",
    "        scores = np.zeros((num_queries, N), dtype=int)\n",
    "\n",
    "        for i, targets in enumerate(self._scores_map.values()):\n",
    "            num_targets = min(len(targets), N)\n",
    "            scores[i, :num_targets] = 1\n",
    "\n",
    "        return scores\n",
    "    \n",
    "    def mean_ndcg(self, search_engine: SearchEngine, N: int) -> float:\n",
    "        predictions = self._eval_queries(search_engine, N)\n",
    "        targets = self._target_scores(N)\n",
    "\n",
    "        dcg_weights = np.log2(np.arange(2, N + 2))\n",
    "        dcg_weights = np.resize(dcg_weights, predictions.shape)\n",
    "        dcg = np.sum(predictions / dcg_weights, axis=1)\n",
    "        idcg = np.sum(targets / dcg_weights, axis=1)\n",
    "        ndcg = dcg / idcg\n",
    "\n",
    "        return ndcg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_benchmark = NDCGBenchmark(queries_df, qa_test_df)\n",
    "\n",
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/06zrhgts1xlbpl77yjk6_83m0000gn/T/ipykernel_72153/2195271707.py:78: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = self._es.search(index=self._index_name, body=query_body) # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 for FTS is: 0.40103115292829833\n"
     ]
    }
   ],
   "source": [
    "fts_ndcg = ndcg_benchmark.mean_ndcg(es_test_search_engine, N)\n",
    "\n",
    "print(f\"NDCG@{N} for FTS is: {fts_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/06zrhgts1xlbpl77yjk6_83m0000gn/T/ipykernel_72153/2195271707.py:78: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = self._es.search(index=self._index_name, body=query_body) # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 for FTS re-ranked by sequence classifier is: 0.4895170370519111\n"
     ]
    }
   ],
   "source": [
    "classifier_re_reanked_fts_ndcq = ndcg_benchmark.mean_ndcg(classifier_search_engine, N)\n",
    "\n",
    "print(f\"NDCG@{N} for FTS re-ranked by sequence classifier is: {classifier_re_reanked_fts_ndcq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do you think simpler methods, like Bayesian bag-of-words model, would work for sentence-pair classification? Justify your answer.\n",
    "\n",
    "Bayesian bag-of-words models typically represent text using word frequencies without considering word order or context. This simplistic representation might struggle with capturing the semantic or syntactic nuances present in sentence pairs, limiting its performance compared to models that capture contextual information like LLMs.\n",
    "\n",
    "## What hyper-parameters you have selected for the training? What resources (papers, tutorial) you have consulted to select these hyper-parameters?\n",
    "\n",
    "I decided to use warmup for the first 10% of the training. Additionally, I used weight_decay (0.001) to prevent overfitting. The learning rate was relatively low: 5e-5. It is worth mentioning that only the last two blocks of the transformer and the classifier layer were tensed - this accelerated the training and enabled the use of a larger batch_size (32). \n",
    "\n",
    "## Think about pros and cons of the neural-network models with respect to natural language processing. Provide at least 2 pros and 2 cons.\n",
    "\n",
    "The advantages of using NN in NLP tasks are certainly the ability to capture the context of sentences, which translates into good results, and the fact that the models learn complex, hierarchical text representations (ebeddings), which allows them to be used for various tasks through fine-tuning.\n",
    "\n",
    "The disadvantages are a large number of parameters, which make training long and consuming many resources, and a long evaluation time, which is a problem in applications where the response time should be short."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
