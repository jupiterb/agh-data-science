{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 \n",
    "Use SpaCy tokenizer API to tokenize the text from the PiQA corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Nie mówię, że nie podoba mi się też pomysł szk...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>Tak więc nic nie zapobiega fałszywym ocenom po...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td></td>\n",
       "      <td>Nigdy nie możesz korzystać z FSA dla indywidua...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td></td>\n",
       "      <td>Samsung stworzył LCD i inne technologie płaski...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td></td>\n",
       "      <td>Oto wymagania SEC: Federalne przepisy dotycząc...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title                                               text metadata\n",
       "_id                                                                  \n",
       "3          Nie mówię, że nie podoba mi się też pomysł szk...       {}\n",
       "31         Tak więc nic nie zapobiega fałszywym ocenom po...       {}\n",
       "56         Nigdy nie możesz korzystać z FSA dla indywidua...       {}\n",
       "59         Samsung stworzył LCD i inne technologie płaski...       {}\n",
       "63         Oto wymagania SEC: Federalne przepisy dotycząc...       {}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = pd.read_json(\"./data/corpus.jsonl\", lines=True)\n",
    "corpus_df = corpus_df.set_index('_id').sort_index()\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "\n",
    "Corpus = Sequence[str]\n",
    "\n",
    "corpus = [row[\"text\"] for _, row in corpus_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish = spacy.load(\"pl_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 \n",
    "Compute bigram counts of downcased tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGrams = dict[str, int]\n",
    "\n",
    "\n",
    "class NGramsEngine:\n",
    "\n",
    "    def __init__(self, nlp) -> None:\n",
    "        self._nlp = nlp\n",
    "        self._tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "\n",
    "    def count_ngrams(\n",
    "            self, corpus: Corpus, n: int, lower: bool = True, lemma_tag: bool = False\n",
    "        ) -> NGrams:\n",
    "        from_token = (\n",
    "            # lemmatization sometimes contains many elements\n",
    "            (lambda t: f\"{''.join(t.lemma_.split())}:{t.tag_}\") if lemma_tag else \n",
    "            (lambda t: t.text)\n",
    "            \n",
    "        )\n",
    "        maybe_lower = (lambda t: t.lower()) if lower else (lambda t: t)\n",
    "        preproc = lambda t: maybe_lower(from_token(t))\n",
    "\n",
    "        nlp = lambda doc: self._nlp(doc) if lemma_tag else doc\n",
    "\n",
    "        ngrams: NGrams = {}\n",
    "        \n",
    "        for doc in self._tokenizer.pipe(corpus):\n",
    "            if len(doc) < n:\n",
    "                break\n",
    "\n",
    "            buffer = []\n",
    "\n",
    "            for token in nlp(doc):\n",
    "                buffer.append(preproc(token))\n",
    "\n",
    "                if len(buffer) < n:\n",
    "                    continue\n",
    "\n",
    "                ngram = \" \".join(buffer)\n",
    "                ngrams[ngram] = ngrams.get(ngram, 0) + 1\n",
    "                buffer.pop(0)\n",
    "\n",
    "        return ngrams\n",
    "    \n",
    "\n",
    "ngrams_engine = NGramsEngine(polish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the quick brown': 1,\n",
       " 'quick brown fox': 1,\n",
       " 'brown fox jumps': 1,\n",
       " 'fox jumps over': 1,\n",
       " 'jumps over the': 1,\n",
       " 'over the lazy': 1,\n",
       " 'the lazy dog.': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_engine.count_ngrams([\"The quick brown fox jumps over the lazy dog.\"], n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = ngrams_engine.count_ngrams(corpus, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "Discard bigrams containing characters other than letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(ngrams: NGrams, predicate) -> NGrams:\n",
    "    return {\n",
    "        ngram: count \n",
    "        for ngram, count in ngrams.items()\n",
    "        if predicate(ngram, count)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "\n",
    "\n",
    "not_only_letters = r\"[^\\p{L}\\u0100-\\u017F\\s]+\"\n",
    "\n",
    "\n",
    "def filter_only_letters(ngrams: NGrams) -> NGrams:\n",
    "    predicate = lambda ngram, _: re.search(not_only_letters, ngram) is None\n",
    "    return filter(ngrams, predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = filter_only_letters(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "Compute the pointwise mutual information for all pairs of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def pmi(bigrams: NGrams, unigrams: NGrams) -> dict[str, float]:\n",
    "    result = {}\n",
    "\n",
    "    total_bigrams = sum(bigrams.values())\n",
    "    total_unigrams = sum(unigrams.values())\n",
    "\n",
    "    for bigram, count in bigrams.items():\n",
    "        x, y = bigram.split()\n",
    "        \n",
    "        ratio = (count * total_unigrams**2) / (total_bigrams * unigrams[x] * unigrams[y])\n",
    "\n",
    "        result[bigram] = np.log2(ratio)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = ngrams_engine.count_ngrams(corpus, n=1)\n",
    "unigrams = filter_only_letters(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_pmi = pmi(bigrams, unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "Sort the word pairs according to that measure in the descending order and determine top 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_by_values(d: dict) -> list[tuple]:\n",
    "    return [(k, v) for k, v in sorted(d.items(), key=lambda p: p[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('zadłużonych studentów', 16.413533185693815),\n",
       " ('uniemożliwiają instytucjom', 16.413533185693815),\n",
       " ('należytej staranności', 16.413533185693815),\n",
       " ('technologie płaskiego', 16.413533185693815),\n",
       " ('fabryk samsunga', 16.413533185693815),\n",
       " ('dzieła randa', 16.413533185693815),\n",
       " ('strip john', 16.413533185693815),\n",
       " ('john galt', 16.413533185693815),\n",
       " ('sucho wpychanie', 16.413533185693815),\n",
       " ('miliarderów polityków', 16.413533185693815)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_pmi_ordered = order_by_values(bigrams_pmi)\n",
    "bigrams_pmi_ordered[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "Filter bigrams with number of occurrences lower than 5. Determine top 10 entries for the remaining dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('konstruktywne opinie', 16.033649435185765),\n",
       " ('dyrektor generalny', 16.033649435185765),\n",
       " ('paliwa ciekłego', 15.99300745068842),\n",
       " ('agencje ratingowe', 15.84100435724337),\n",
       " ('zbiorniku magazynowym', 15.519076262356009),\n",
       " ('trend wzrostowy', 15.519076262356009),\n",
       " ('kredytów hipotecznych', 15.381572738606074),\n",
       " ('sygnałów elektrycznych', 15.381572738606074),\n",
       " ('of america', 15.256041856522215),\n",
       " ('kredyty hipoteczne', 15.256041856522215)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_filtered = filter(bigrams, lambda _, count: count >= 5)\n",
    "\n",
    "bigrams_filtered_pmi = pmi(bigrams_filtered, unigrams)\n",
    "\n",
    "bigrams_filtered_pmi_ordered = order_by_values(bigrams_filtered_pmi)\n",
    "bigrams_filtered_pmi_ordered[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7-9\n",
    "Use SpaCy to lemmatize and tag the sentences in the corpus.\n",
    "Using the tagged corpus compute bigram statistic for the tokens containing:\n",
    "- lemmatized, downcased word.\n",
    "- morphosyntactic category of the word (subst, fin, adj, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ala:subst mieć:fin': 1, 'mieć:fin kota.:qub': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_engine.count_ngrams([\"Ala ma kota.\"], n=2, lemma_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_lemma = ngrams_engine.count_ngrams(corpus, n=2, lemma_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_only_letters_lemma(ngrams: NGrams) -> NGrams:\n",
    "    predicate = lambda ngram, _: all(\n",
    "        [re.search(not_only_letters, gram.split(\":\")[0]) is None for gram in ngram.split()]\n",
    "    )\n",
    "    return filter(ngrams, predicate)\n",
    "\n",
    "\n",
    "bigrams_lemma = filter_only_letters_lemma(bigrams_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 10\n",
    "Compute the same statistics as for the non-lemmatized words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_lemma = ngrams_engine.count_ngrams(corpus, n=1, lemma_tag=True)\n",
    "unigrams_lemma = filter_only_letters_lemma(unigrams_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_lemma_pmi = pmi(bigrams_lemma, unigrams_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('należyty:adj staranność:subst', 16.413413983248002),\n",
       " ('sam::subst strip:subst', 16.413413983248002),\n",
       " ('strip:subst john:subst', 16.413413983248002),\n",
       " ('john:subst galt:subst', 16.413413983248002),\n",
       " ('sucho:adv wpychanie:ger', 16.413413983248002),\n",
       " ('miliarder:subst polityk:subst', 16.413413983248002),\n",
       " ('kursow:adj wynikającego:pact', 16.413413983248002),\n",
       " ('toronto:subst star:subst', 16.413413983248002),\n",
       " ('sądach:subst okręgowy:adj', 16.413413983248002),\n",
       " ('zobaczyć:subst poniższ:fin', 16.413413983248002)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_lemma_pmi_ordered = order_by_values(bigrams_lemma_pmi)\n",
    "bigrams_lemma_pmi_ordered[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paliwo:subst ciekły:adj', 15.234722440568252),\n",
       " ('of:subst america:subst', 14.997683243267403),\n",
       " ('konstruktywny:adj opinia:subst', 14.872152361183543),\n",
       " ('zbiornik:subst magazynowy:adj', 14.872152361183543),\n",
       " ('dyrektor:subst generalny:adj', 14.4571148619047),\n",
       " ('trend:subst wzrostowy:adj', 14.287189860462387),\n",
       " ('opieka:subst zdrowotny:adj', 14.177006942711964),\n",
       " ('działalność:subst gospodarczy:adj', 14.024155454628595),\n",
       " ('gospodarstwo:subst domowy:adj', 13.779042956792063),\n",
       " ('sygnał:subst elektryczny:adj', 13.708176626072419)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_lemma_filtered = filter(bigrams_lemma, lambda _, count: count >= 5)\n",
    "\n",
    "bigrams_lemma_filtered_pmi = pmi(bigrams_lemma_filtered, unigrams_lemma)\n",
    "\n",
    "bigrams_lemma_filtered_pmi_ordered = order_by_values(bigrams_lemma_filtered_pmi)\n",
    "bigrams_lemma_filtered_pmi_ordered[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 11-12\n",
    "Group the bigrams by morphosyntactic tag.\n",
    "Print top-10 categories and print top-5 pairs for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_tag(ngrams: NGrams) -> dict[str, NGrams]:\n",
    "    groups = {}\n",
    "\n",
    "    get_tags = lambda ngram: \" \".join([lemma_tag.split(\":\")[1] for lemma_tag in ngram.split()])\n",
    "\n",
    "    for ngram, count in ngrams.items():\n",
    "        tags = get_tags(ngram)\n",
    "        if tags not in groups:\n",
    "            groups[tags] = {}\n",
    "        groups[tags][ngram] = count\n",
    "\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_lemma_grouped = group_by_tag(bigrams_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_total_count = {tags: sum(group.values()) for tags, group in bigrams_lemma_grouped.items()}\n",
    "groups_total_count_ordered = order_by_values(groups_total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] category: (adj subst), total count: 3736\n",
      "(ten:adj sposób:subst) 16 | (drugi:adj strona:subst) 15 | (taki:adj przypadek:subst) 13 | (twój:adj firma:subst) 12 | (ten:adj wszystko:subst) 10\n",
      "[2] category: (prep subst), total count: 3521\n",
      "(w:prep przypadek:subst) 73 | (w:prep ciąg:subst) 45 | (w:prep stan:subst) 42 | (na:prep przykład:subst) 39 | (w:prep zależność:subst) 35\n",
      "[3] category: (subst prep), total count: 3317\n",
      "(zależność:subst od:prep) 37 | (pieniądz:subst na:prep) 37 | (wzgląd:subst na:prep) 35 | (podatek:subst od:prep) 32 | (opłata:subst za:prep) 24\n",
      "[4] category: (subst subst), total count: 2606\n",
      "(cena:subst akcja:subst) 21 | (wartość:subst firma:subst) 9 | (miejsce:subst praca:subst) 8 | (punkt:subst widzenie:subst) 8 | (spłata:subst kredyt:subst) 8\n",
      "[5] category: (prep adj), total count: 2095\n",
      "(w:prep ten:adj) 96 | (w:prep który:adj) 95 | (z:prep ten:adj) 51 | (na:prep ten:adj) 39 | (dla:prep który:adj) 30\n",
      "[6] category: (subst fin), total count: 2010\n",
      "(co:subst być:fin) 32 | (to:subst być:fin) 22 | (co:subst móc:fin) 18 | (akcja:subst być:fin) 15 | (firma:subst być:fin) 12\n",
      "[7] category: (subst adj), total count: 1932\n",
      "(kredyt:subst hipoteczny:adj) 30 | (stopa:subst procentowy:adj) 25 | (karta:subst kredytowy:adj) 22 | (stany:subst zjednoczone:adj) 20 | (zysk:subst kapitałowy:adj) 19\n",
      "[8] category: (subst conj), total count: 1247\n",
      "(akcja:subst i:conj) 14 | (rok:subst i:conj) 13 | (praca:subst i:conj) 13 | (firma:subst i:conj) 12 | (bank:subst i:conj) 10\n",
      "[9] category: (qub fin), total count: 1078\n",
      "(nie:qub być:fin) 229 | (nie:qub mieć:fin) 154 | (nie:qub móc:fin) 88 | (czy:qub być:fin) 29 | (nie:qub musieć:fin) 26\n",
      "[10] category: (fin subst), total count: 1014\n",
      "(móc:fin to:subst) 29 | (być:fin to:subst) 28 | (mieć:fin to:subst) 10 | (pobierać:fin opłata:subst) 10 | (robić:fin to:subst) 9\n"
     ]
    }
   ],
   "source": [
    "for i, (tags, total_count) in enumerate(groups_total_count_ordered[:10]):\n",
    "    print(f\"[{i+1}] category: ({tags}), total count: {total_count}\")\n",
    "    group_ordered = order_by_values(bigrams_lemma_grouped[tags])\n",
    "    print(\" | \".join([f\"({bigram}) {count}\" for bigram, count in group_ordered[:5]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 13\n",
    "Table comparing the results for copora without and with tagging and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top PMI no lemma no filter</th>\n",
       "      <th>Top PMI no lemma with filter</th>\n",
       "      <th>Top PMI with lemma no filter</th>\n",
       "      <th>Top PMI with lemma with filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(zadłużonych studentów, 16.413533185693815)</td>\n",
       "      <td>(konstruktywne opinie, 16.033649435185765)</td>\n",
       "      <td>(należyty:adj staranność:subst, 16.41341398324...</td>\n",
       "      <td>(paliwo:subst ciekły:adj, 15.234722440568252)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(uniemożliwiają instytucjom, 16.413533185693815)</td>\n",
       "      <td>(dyrektor generalny, 16.033649435185765)</td>\n",
       "      <td>(sam::subst strip:subst, 16.413413983248002)</td>\n",
       "      <td>(of:subst america:subst, 14.997683243267403)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(należytej staranności, 16.413533185693815)</td>\n",
       "      <td>(paliwa ciekłego, 15.99300745068842)</td>\n",
       "      <td>(strip:subst john:subst, 16.413413983248002)</td>\n",
       "      <td>(konstruktywny:adj opinia:subst, 14.8721523611...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(technologie płaskiego, 16.413533185693815)</td>\n",
       "      <td>(agencje ratingowe, 15.84100435724337)</td>\n",
       "      <td>(john:subst galt:subst, 16.413413983248002)</td>\n",
       "      <td>(zbiornik:subst magazynowy:adj, 14.87215236118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(fabryk samsunga, 16.413533185693815)</td>\n",
       "      <td>(zbiorniku magazynowym, 15.519076262356009)</td>\n",
       "      <td>(sucho:adv wpychanie:ger, 16.413413983248002)</td>\n",
       "      <td>(dyrektor:subst generalny:adj, 14.4571148619047)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(dzieła randa, 16.413533185693815)</td>\n",
       "      <td>(trend wzrostowy, 15.519076262356009)</td>\n",
       "      <td>(miliarder:subst polityk:subst, 16.41341398324...</td>\n",
       "      <td>(trend:subst wzrostowy:adj, 14.287189860462387)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(strip john, 16.413533185693815)</td>\n",
       "      <td>(kredytów hipotecznych, 15.381572738606074)</td>\n",
       "      <td>(kursow:adj wynikającego:pact, 16.413413983248...</td>\n",
       "      <td>(opieka:subst zdrowotny:adj, 14.177006942711964)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(john galt, 16.413533185693815)</td>\n",
       "      <td>(sygnałów elektrycznych, 15.381572738606074)</td>\n",
       "      <td>(toronto:subst star:subst, 16.413413983248002)</td>\n",
       "      <td>(działalność:subst gospodarczy:adj, 14.0241554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(sucho wpychanie, 16.413533185693815)</td>\n",
       "      <td>(of america, 15.256041856522215)</td>\n",
       "      <td>(sądach:subst okręgowy:adj, 16.413413983248002)</td>\n",
       "      <td>(gospodarstwo:subst domowy:adj, 13.77904295679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(miliarderów polityków, 16.413533185693815)</td>\n",
       "      <td>(kredyty hipoteczne, 15.256041856522215)</td>\n",
       "      <td>(zobaczyć:subst poniższ:fin, 16.413413983248002)</td>\n",
       "      <td>(sygnał:subst elektryczny:adj, 13.708176626072...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Top PMI no lemma no filter  \\\n",
       "0       (zadłużonych studentów, 16.413533185693815)   \n",
       "1  (uniemożliwiają instytucjom, 16.413533185693815)   \n",
       "2       (należytej staranności, 16.413533185693815)   \n",
       "3       (technologie płaskiego, 16.413533185693815)   \n",
       "4             (fabryk samsunga, 16.413533185693815)   \n",
       "5                (dzieła randa, 16.413533185693815)   \n",
       "6                  (strip john, 16.413533185693815)   \n",
       "7                   (john galt, 16.413533185693815)   \n",
       "8             (sucho wpychanie, 16.413533185693815)   \n",
       "9       (miliarderów polityków, 16.413533185693815)   \n",
       "\n",
       "                   Top PMI no lemma with filter  \\\n",
       "0    (konstruktywne opinie, 16.033649435185765)   \n",
       "1      (dyrektor generalny, 16.033649435185765)   \n",
       "2          (paliwa ciekłego, 15.99300745068842)   \n",
       "3        (agencje ratingowe, 15.84100435724337)   \n",
       "4   (zbiorniku magazynowym, 15.519076262356009)   \n",
       "5         (trend wzrostowy, 15.519076262356009)   \n",
       "6   (kredytów hipotecznych, 15.381572738606074)   \n",
       "7  (sygnałów elektrycznych, 15.381572738606074)   \n",
       "8              (of america, 15.256041856522215)   \n",
       "9      (kredyty hipoteczne, 15.256041856522215)   \n",
       "\n",
       "                        Top PMI with lemma no filter  \\\n",
       "0  (należyty:adj staranność:subst, 16.41341398324...   \n",
       "1       (sam::subst strip:subst, 16.413413983248002)   \n",
       "2       (strip:subst john:subst, 16.413413983248002)   \n",
       "3        (john:subst galt:subst, 16.413413983248002)   \n",
       "4      (sucho:adv wpychanie:ger, 16.413413983248002)   \n",
       "5  (miliarder:subst polityk:subst, 16.41341398324...   \n",
       "6  (kursow:adj wynikającego:pact, 16.413413983248...   \n",
       "7     (toronto:subst star:subst, 16.413413983248002)   \n",
       "8    (sądach:subst okręgowy:adj, 16.413413983248002)   \n",
       "9   (zobaczyć:subst poniższ:fin, 16.413413983248002)   \n",
       "\n",
       "                      Top PMI with lemma with filter  \n",
       "0      (paliwo:subst ciekły:adj, 15.234722440568252)  \n",
       "1       (of:subst america:subst, 14.997683243267403)  \n",
       "2  (konstruktywny:adj opinia:subst, 14.8721523611...  \n",
       "3  (zbiornik:subst magazynowy:adj, 14.87215236118...  \n",
       "4   (dyrektor:subst generalny:adj, 14.4571148619047)  \n",
       "5    (trend:subst wzrostowy:adj, 14.287189860462387)  \n",
       "6   (opieka:subst zdrowotny:adj, 14.177006942711964)  \n",
       "7  (działalność:subst gospodarczy:adj, 14.0241554...  \n",
       "8  (gospodarstwo:subst domowy:adj, 13.77904295679...  \n",
       "9  (sygnał:subst elektryczny:adj, 13.708176626072...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(\n",
    "    {\n",
    "        \"Top PMI no lemma no filter\": bigrams_pmi_ordered[:10],\n",
    "        \"Top PMI no lemma with filter\": bigrams_filtered_pmi_ordered[:10],\n",
    "        \"Top PMI with lemma no filter\": bigrams_lemma_pmi_ordered[:10],\n",
    "        \"Top PMI with lemma with filter\": bigrams_lemma_filtered_pmi_ordered[:10]\n",
    "    }\n",
    ")\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we have to filter the bigrams, rather than the token sequence?\n",
    "\n",
    "If we filter tokens before building bigrams, tokens that were not previously adjacent are next to each other and can be used to build a bigram that does not actually exist.\n",
    "\n",
    "## What types of expressions are discovered by the methods?\n",
    "\n",
    "It seems that PMI with filtering is pretty good at discovering bigrams with words that are commonly used together, like \"konstruktywne opinie\" and on the other hand, are pretty popular. \n",
    "At the same time, if we don't use filtering, we get bigrams that most probably occured only once.\n",
    "\n",
    "## Can you devise a different type of filtering that would yield better results?\n",
    "\n",
    "Probably we can remove documents that are not in specific language."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
