{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "test_passages_df = pd.read_json(\n",
    "    \"./data/simple-legal-questions-pl/passages.jl\", lines=True\n",
    ").set_index(\"_id\").sort_index()\n",
    "\n",
    "test_questions_df = pd.read_json(\n",
    "    \"./data/simple-legal-questions-pl/questions.jl\", lines=True\n",
    ").set_index(\"_id\").sort_index()\n",
    "\n",
    "test_answers_df = pd.read_json(\n",
    "    \"./data/simple-legal-questions-pl/answers.jl\", lines=True\n",
    ").set_index(\"question-id\").sort_index()\n",
    "\n",
    "test_relevant_df = pd.read_json(\n",
    "    \"./data/simple-legal-questions-pl/relevant.jl\", lines=True\n",
    ").set_index(\"question-id\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993_599_1</th>\n",
       "      <td>Ustawa z dnia 9 grudnia 1993 r. o zmianie usta...</td>\n",
       "      <td>Art. 1. W ustawie z dnia 8 stycznia 1993 r. o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993_599_2</th>\n",
       "      <td>Ustawa z dnia 9 grudnia 1993 r. o zmianie usta...</td>\n",
       "      <td>Art. 2. W okresie od dnia wejścia w życie usta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993_599_3</th>\n",
       "      <td>Ustawa z dnia 9 grudnia 1993 r. o zmianie usta...</td>\n",
       "      <td>Art. 3. Minister Finansów ogłosi w Dzienniku U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993_599_4</th>\n",
       "      <td>Ustawa z dnia 9 grudnia 1993 r. o zmianie usta...</td>\n",
       "      <td>Art. 4. Ustawa wchodzi w życie z dniem 1 stycz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993_602_1</th>\n",
       "      <td>Ustawa z dnia 10 grudnia 1993 r. o zmianie nie...</td>\n",
       "      <td>Art. 1. W ustawie z dnia 29 maja 1974 r. o zao...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "_id                                                             \n",
       "1993_599_1  Ustawa z dnia 9 grudnia 1993 r. o zmianie usta...   \n",
       "1993_599_2  Ustawa z dnia 9 grudnia 1993 r. o zmianie usta...   \n",
       "1993_599_3  Ustawa z dnia 9 grudnia 1993 r. o zmianie usta...   \n",
       "1993_599_4  Ustawa z dnia 9 grudnia 1993 r. o zmianie usta...   \n",
       "1993_602_1  Ustawa z dnia 10 grudnia 1993 r. o zmianie nie...   \n",
       "\n",
       "                                                         text  \n",
       "_id                                                            \n",
       "1993_599_1  Art. 1. W ustawie z dnia 8 stycznia 1993 r. o ...  \n",
       "1993_599_2  Art. 2. W okresie od dnia wejścia w życie usta...  \n",
       "1993_599_3  Art. 3. Minister Finansów ogłosi w Dzienniku U...  \n",
       "1993_599_4  Art. 4. Ustawa wchodzi w życie z dniem 1 stycz...  \n",
       "1993_602_1  Art. 1. W ustawie z dnia 29 maja 1974 r. o zao...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_passages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Czy żołnierz, który dopuszcza się czynnej napa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z ilu osób składa się komisja przetargowa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do jakiej wysokości za zobowiązania spółki odp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kiedy ustala się wartość majątku obrotowego, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jakiej karze podlega armator, który wykonuje r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "_id                                                   \n",
       "1    Czy żołnierz, który dopuszcza się czynnej napa...\n",
       "2           Z ilu osób składa się komisja przetargowa?\n",
       "3    Do jakiej wysokości za zobowiązania spółki odp...\n",
       "4    Kiedy ustala się wartość majątku obrotowego, k...\n",
       "5    Jakiej karze podlega armator, który wykonuje r..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Tak, podlega karze aresztu wojskowego albo poz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Komisja przetargowa składa się z co najmniej t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Komandytariusz odpowiada za zobowiązania spółk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Wartość rzeczowych składników majątku obrotowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Podlega karze pieniężnej do wysokości 1 000 00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             score                                             answer\n",
       "question-id                                                          \n",
       "1              1.0  Tak, podlega karze aresztu wojskowego albo poz...\n",
       "2              1.0  Komisja przetargowa składa się z co najmniej t...\n",
       "3              1.0  Komandytariusz odpowiada za zobowiązania spółk...\n",
       "4              1.0  Wartość rzeczowych składników majątku obrotowe...\n",
       "5              1.0  Podlega karze pieniężnej do wysokości 1 000 00..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_answers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_553_345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004_177_21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996_465_111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994_591_35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001_1441_74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               passage-id  score\n",
       "question-id                     \n",
       "1            1997_553_345      1\n",
       "2             2004_177_21      1\n",
       "3            1996_465_111      1\n",
       "4             1994_591_35      1\n",
       "5            2001_1441_74      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relevant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before fitter: 638\n",
      "Number of rows after fitter: 636\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows before fitter: {len(test_answers_df)}\")\n",
    "\n",
    "test_answers_df = test_answers_df[\n",
    "    (test_answers_df[\"score\"] == 0) | (test_answers_df[\"score\"] == 1)\n",
    "]\n",
    "\n",
    "print(f\"Number of rows after fitter: {len(test_answers_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"./data/poquad-dev.json\") as f:\n",
    "    poquad_dev = json.load(f)[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8\n",
    "Use apohllo/plt5-base-poquad which was trained on PoQuAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "source": [
    "from torch import no_grad, backends, device\n",
    "\n",
    "\n",
    "if backends.mps.is_available():\n",
    "    current_device = device(\"mps\")\n",
    "else:\n",
    "    current_device = device(\"cpu\")\n",
    "    \n",
    "print(f\"Device is {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrbialy/Projects/agh-data-science/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "\n",
    "class QuestionAnswering:\n",
    "    def __init__(self, model_name: str, device) -> None:\n",
    "        self._model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self._device = device\n",
    "\n",
    "    def answer(self, question: str, context: str, p_limit: float = 0.9, k_limit: int = 50) -> str:\n",
    "        input_text = f\"Pytanie: {question}. Kontekst: {context}\"\n",
    "        \n",
    "        tokens = self._tokenizer.encode(\n",
    "            input_text, \n",
    "            return_tensors=\"pt\",\n",
    "        ).to(self._device)\n",
    "\n",
    "        with no_grad():\n",
    "            outputs = self._model.generate(\n",
    "                tokens, \n",
    "                max_length=1000, \n",
    "                do_sample=True, \n",
    "                top_p=p_limit, \n",
    "                top_k=k_limit,\n",
    "            )\n",
    "\n",
    "        output_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"apohllo/plt5-base-poquad\"\n",
    "\n",
    "qa = QuestionAnswering(model_name, current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: Z ilu osób składa się komisja przetargowa?\n",
      "context: Art. 21. 1. Członków komisji przetargowej powołuje i odwołuje kierownik zamawiającego. 2. Komisja przetargowa składa się z co najmniej trzech osób. 3. Kierownik zamawiającego określa organizację, skład, tryb pracy oraz zakres obowiązków członków komisji przetargowej, mając na celu zapewnienie sprawności jej działania, indywidualizacji odpowiedzialności jej członków za wykonywane czynności oraz przejrzystości jej prac. 4. Jeżeli dokonanie określonych czynności związanych z przygotowaniem i przeprowadzeniem postępowania o udzielenie zamówienia wymaga wiadomości specjalnych, kierownik zamawiającego, z własnej inicjatywy lub na wniosek komisji przetargowej, może powołać biegłych. Przepis art. 17 stosuje się.\n",
      "answer: trzech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrbialy/Projects/agh-data-science/venv/lib/python3.11/site-packages/transformers/generation/logits_process.py:451: UserWarning: torch.topk support for k>16 by MPS on MacOS 13+, please upgrade (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Shape.mm:71.)\n",
      "  indices_to_remove = scores < torch.topk(scores, top_k)[0][..., -1, None]\n",
      "/Users/piotrbialy/Projects/agh-data-science/venv/lib/python3.11/site-packages/transformers/generation/logits_process.py:413: UserWarning: torch.sort is supported by MPS on MacOS 13+, please upgrade. Falling back to CPU (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Sort.mm:41.)\n",
      "  sorted_logits, sorted_indices = torch.sort(scores, descending=False)\n",
      "/Users/piotrbialy/Projects/agh-data-science/venv/lib/python3.11/site-packages/transformers/generation/logits_process.py:414: UserWarning: cumsum_out_mps supported by MPS on MacOS 13+, please upgrade (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/UnaryOps.mm:406.)\n",
      "  cumulative_probs = sorted_logits.softmax(dim=-1).cumsum(dim=-1)\n",
      "/Users/piotrbialy/Projects/agh-data-science/venv/lib/python3.11/site-packages/transformers/generation/utils.py:2860: UserWarning: MPS: no support for int64 for min_max, downcasting to a smaller data type (int32/float32). Native support for int64 has been added in macOS 13.3. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:621.)\n",
      "  if unfinished_sequences.max() == 0:\n"
     ]
    }
   ],
   "source": [
    "_id = 2\n",
    "_question = test_questions_df.loc[_id][\"text\"]\n",
    "_context = test_passages_df.loc[test_relevant_df.loc[_id][\"passage-id\"]][\"text\"]\n",
    "\n",
    "_answer = qa.answer(question=_question, context=_context)\n",
    "\n",
    "print(f\"question: {_question}\")\n",
    "print(f\"context: {_context}\")\n",
    "print(f\"answer: {_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 9-10\n",
    "Report the obtained performance of the model (in the form of a table). The report should include exact match and F1 score for the tokens appearing both in the reference and the predicted answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def normalize_answer(s: str) -> str:\n",
    "    return \" \".join(re.sub(f\"[{string.punctuation}]\", \"\", s.lower()).split())\n",
    "\n",
    "\n",
    "def exact_match_score(prediction: str, truth: str) -> int:\n",
    "    return int(normalize_answer(prediction) == normalize_answer(truth))\n",
    "\n",
    "\n",
    "def f1_score(prediction: str, truth: str) -> float:\n",
    "    def calculate_f1(precision, recall):\n",
    "        if precision + recall == 0:\n",
    "            return 0.0\n",
    "        return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    pred_tokens = normalize_answer(prediction).split()\n",
    "    truth_tokens = normalize_answer(truth).split()\n",
    "\n",
    "    common = Counter(pred_tokens) & Counter(truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "\n",
    "    precision = num_same / len(pred_tokens) if len(pred_tokens) > 0 else 0\n",
    "    recall = num_same / len(truth_tokens) if len(truth_tokens) > 0 else 0\n",
    "\n",
    "    return calculate_f1(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "for qid, row in test_relevant_df.iterrows():\n",
    "    try:\n",
    "        item = (\n",
    "            test_questions_df.loc[qid][\"text\"],\n",
    "            test_passages_df.loc[test_relevant_df.loc[qid][\"passage-id\"]][\"text\"],\n",
    "            test_answers_df.loc[qid][\"answer\"],\n",
    "        ) \n",
    "        test_data.append(item)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "\n",
    "validation_data = []\n",
    "\n",
    "for article in poquad_dev:\n",
    "    \n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]\n",
    "\n",
    "        for question_answer in paragraph[\"qas\"]:\n",
    "            question = question_answer[\"question\"]\n",
    "\n",
    "            answer = (\n",
    "                question_answer[\"answers\"][0][\"generative_answer\"] \n",
    "                if \"answers\" in question_answer \n",
    "                else \"\"\n",
    "            )\n",
    "            \n",
    "            item = (question, context, answer)\n",
    "            validation_data.append(item)\n",
    "\n",
    "validation_data_sample = sample(validation_data, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def eval_qa(qa: QuestionAnswering, data: Sequence[tuple[str, str, str]]) -> tuple[float, float]:\n",
    "    exact_matches = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for question, context, true_answer in tqdm(data):\n",
    "        predicted_answer = qa.answer(question, context)\n",
    "\n",
    "        exact_matches.append(exact_match_score(predicted_answer, true_answer))\n",
    "        f1_scores.append(f1_score(predicted_answer, true_answer))\n",
    "\n",
    "    return (\n",
    "        np.mean(exact_matches, dtype=float),\n",
    "        np.mean(f1_scores, dtype=float),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 636/636 [10:47<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "test_exact_match, test_f1_score = eval_qa(qa, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for test data: \n",
      "Exact match: 0.24528301886792453\n",
      "F1 score: 0.44090072893385934\n"
     ]
    }
   ],
   "source": [
    "print(f\"Scores for test data: \\nExact match: {test_exact_match}\\nF1 score: {test_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [44:46<00:00,  1.49it/s]   \n"
     ]
    }
   ],
   "source": [
    "validation_exact_match, validation_f1_score = eval_qa(qa, validation_data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for validation data: \n",
      "Exact match: 0.42975\n",
      "F1 score: 0.5745871322790022\n"
     ]
    }
   ],
   "source": [
    "print(f\"Scores for validation data: \\nExact match: {validation_exact_match}\\nF1 score: {validation_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 11\n",
    "Generate, report and analyze the answers for at least 10 questions provided by the best model on you test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_question(data: Sequence[tuple[str, str, str]], qa: QuestionAnswering, index: int) -> None:\n",
    "    question, context, true_answer = data[index]\n",
    "    predicted_answer = qa.answer(question, context)\n",
    "\n",
    "    print(f\"    Index: {index}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Context: {context}\")\n",
    "    print(f\"True answer: {true_answer}\")\n",
    "    print(f\"Predicted answer: {predicted_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0, 3, 120, 145, 150, 748, 1720, 1723, 1746, 1324]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Index: 0\n",
      "Question: Czym są pisma rabiniczne?\n",
      "Context: Pisma rabiniczne – w tym Miszna – stanowią kompilację poglądów różnych rabinów na określony temat. Zgodnie z wierzeniami judaizmu Mojżesz otrzymał od Boga całą Torę, ale w dwóch częściach: jedną część w formie pisanej, a drugą część w formie ustnej. Miszna – jako Tora ustna – była traktowana nie tylko jako uzupełnienie Tory spisanej, ale również jako jej interpretacja i wyjaśnienie w konkretnych sytuacjach życiowych. Tym samym Miszna stanowiąca kodeks Prawa religijnego zaczęła równocześnie służyć za jego ustnie przekazywany podręcznik.\n",
      "True answer: kompilacją poglądów różnych rabinów na określony temat\n",
      "Predicted answer: kompilacją poglądów różnych rabinów na określony temat\n",
      "    Index: 3\n",
      "Question: W jakiej formie przekazana została Miszna?\n",
      "Context: Pisma rabiniczne – w tym Miszna – stanowią kompilację poglądów różnych rabinów na określony temat. Zgodnie z wierzeniami judaizmu Mojżesz otrzymał od Boga całą Torę, ale w dwóch częściach: jedną część w formie pisanej, a drugą część w formie ustnej. Miszna – jako Tora ustna – była traktowana nie tylko jako uzupełnienie Tory spisanej, ale również jako jej interpretacja i wyjaśnienie w konkretnych sytuacjach życiowych. Tym samym Miszna stanowiąca kodeks Prawa religijnego zaczęła równocześnie służyć za jego ustnie przekazywany podręcznik.\n",
      "True answer: ustnej\n",
      "Predicted answer: ustnej\n",
      "    Index: 120\n",
      "Question: Dlaczego zaniechano rozbiórki obiektu w latach 70.?\n",
      "Context: 22 stycznia 1973 firma poinformowała o znacznych stratach przynoszonych przez windę i zaproponowała rządowi jej przejęcie. Kilka dni później, 1 lutego 1973, nastąpiło zakończenie działalności. Firma Macartney, McElroy & Co. została zlikwidowana w roku 1975. W latach kolejnych pojawiały się propozycje ponownego uruchomienia windy, jednak nie zostały one zrealizowane. Pod koniec lat 70. XX w. podjęto decyzję o rozbiórce windy, co jednak nie nastąpiło ze względu na znaczne koszty. Ostatecznie rozbiórki dokonano pomiędzy czerwcem a sierpniem 1983.\n",
      "True answer: ze względu na znaczne koszty\n",
      "Predicted answer: ze względu na znaczne koszty\n",
      "    Index: 145\n",
      "Question: Dokąd zmierzał statek zaatakowany 6 października?\n",
      "Context: 6 października 15 Mm na północ od Aleksandrii UC-74 storpedował bez ostrzeżenia i zatopił zbudowany w 1902 roku uzbrojony brytyjski parowiec „Civilian” o pojemności 7871 BRT, przewożący drobnicę z Liverpoolu do Kalkuty (na pokładzie zginęły dwie osoby). 11 października u wybrzeży Egiptu U-Boot zatopił francuski żaglowiec „Panormitis” (59 BRT). Trzy dni później na północ od Krety okręt storpedował bez ostrzeżenia i zatopił zbudowany w 1899 roku uzbrojony brytyjski parowiec „Semantha” o pojemności 2847 BRT, a w wyniku ataku śmierć poniosło 32 członków załogi. 15 października na pozycji 36°13′N 24°33′E/36,216667 24,550000 ten sam los spotkał pochodzący z 1880 roku uzbrojony brytyjski parowiec „White Head” (1172 BRT), który zatonął ze stratą 23 załogantów.\n",
      "True answer: do Kalkuty\n",
      "Predicted answer: do Kalkuty\n",
      "    Index: 150\n",
      "Question: Kogo zagrała aktorka w filmie z serii o Sherlocku Holmesie?\n",
      "Context: Następnym obrazem z McAdams była komedia romantyczna O północy w Paryżu (2011) w reżyserii i według scenariusza Woody’ego Allena, która otworzyła 64. Międzynarodowy Festiwal Filmowy w Cannes. Zagrała w niej postać Inez, płytkiej i filisterskiej narzeczonej głównego bohatera (Owen Wilson). Allen stworzył tę postać z myślą o McAdams, po usłyszeniu pochlebnych opinii na jej temat ze strony Diane Keaton. McAdams powiedziała później, że współpraca z Allenem była wyjątkowym przeżyciem i niezwykłym w porównaniu z innymi filmami. Krytycy chwalili film Allena, jednakże McAdams zebrała chłodne opinie odnośnie do swojej gry; jeden z recenzentów określił jej rolę jako „naprawdę niewdzięczną”. Przyniósł on w Ameryce najwyższy przychód brutto (bez uwzględnienia inflacji) spośród wszystkich dotychczasowych filmów Allena i był najbardziej dochodowym filmem kina niezależnego w 2011. Przy budżecie 17 mln USD, film zarobił na świecie ponad 151 mln USD. McAdams, wraz z innymi sześcioma członkami obsady, była nominowana do Nagrody Gildii Aktorów Ekranowych za wybitny występ zespołu aktorskiego w filmie kinowym. Woody Allen zdobył Oskara za najlepszy scenariusz, a film był nominowany do nagrody w 3 kategoriach, w tym za najlepszy film. McAdams ponownie wcieliła się w rolę Irene Adler w sequelu Sherlock Holmes: Gra cieni, jednak główną rolę żeńską otrzymała Noomi Rapace. Joel Silver, producent filmu, powiedział w wywiadzie, że „zawsze zamierzaliśmy angażować do każdego filmu inną dziewczynę” podobnie jak „dziewczyny Bonda” w filmach z Jamesem Bodem. Stwierdził, że „było skomplikowaną sprawą” przekonać McAdams, żeby powróciła w mniejszej roli: „Ona uwielbiała pracować z nami, ale miała nadzieję na większą rolę”. Jej występ został pozytywnie oceniony m.in. w The Wall Street Journal i The Huffington Post. Film zarobił na świecie ponad 545 mln USD.\n",
      "True answer: Irene Adler\n",
      "Predicted answer: Irene Adler\n",
      "    Index: 748\n",
      "Question: W jakim mieście rozgrywa się główna akcja noweli \"Latarnik\"?\n",
      "Context: Bohaterem noweli jest Polak Skawiński, który przybywa do Aspinwall, aby tu objąć posadę latarnika. Jest zmęczony życiem, które obfitowało w przygody, zwykle kończące się dla Skawińskiego katastrofą. Wziąwszy udział w powstaniu, musiał opuścić kraj, tułał się po całym świecie, wiele razy ryzykując życie. W końcu zaczął szukać miejsca, w którym na dobre mógłby się osiedlić. Wybrał Aspinwall i latarnię morską, gdzie rozpoczął ciche, spokojne życie. Wiele rozmyślał i wspominał, nie zaniedbując nigdy swoich obowiązków. Podziwiał tropikalną przyrodę, zaprzyjaźnił się z odwiedzającymi jego latarnię mewami.\n",
      "True answer: Aspinwall\n",
      "Predicted answer: Aspinwall\n",
      "    Index: 1720\n",
      "Question: W którym roku Piszczek zaczął grać w Zagłębiu Lublin?\n",
      "Context: Łukasz Piszczek do Zagłębia Lubin dołączył w 2004 – został wypożyczony z Herthy. W Ekstraklasie zadebiutował 16 października 2004 w meczu z GKS-em Katowice (7:0). To spotkanie rozpoczął z ławki rezerwowych, lecz w 55. minucie wszedł na plac gry zmieniając Łukasza Mierzejewskiego. Pierwszą bramkę w polskiej lidze zdobył 13 listopada 2004 w meczu z Górnikiem Polkowice (2:0). W sumie w sezonie 2004/2005 zagrał w 11 meczach ligowych, w których zdobył 2 gole. W kolejnym sezonie grał już regularnie- w 28 meczach zdobył jedną bramkę. Sezon 2006/2007 zarówno dla Piszczka, jak i dla całej drużyny „Miedziowych” był bardzo udany – Zagłębie Lubin po raz drugi w swojej historii zdobyło mistrzostwo Polski, a Łukasz Piszczek z jedenastoma trafieniami został trzecim strzelcem sezonu. Po zakończeniu sezonu Piszczek powrócił do Herthy.\n",
      "True answer: 2004\n",
      "Predicted answer: 2004\n",
      "    Index: 1723\n",
      "Question: Czy klub Piszczka wygrał mistrzostwa Polski?\n",
      "Context: Łukasz Piszczek do Zagłębia Lubin dołączył w 2004 – został wypożyczony z Herthy. W Ekstraklasie zadebiutował 16 października 2004 w meczu z GKS-em Katowice (7:0). To spotkanie rozpoczął z ławki rezerwowych, lecz w 55. minucie wszedł na plac gry zmieniając Łukasza Mierzejewskiego. Pierwszą bramkę w polskiej lidze zdobył 13 listopada 2004 w meczu z Górnikiem Polkowice (2:0). W sumie w sezonie 2004/2005 zagrał w 11 meczach ligowych, w których zdobył 2 gole. W kolejnym sezonie grał już regularnie- w 28 meczach zdobył jedną bramkę. Sezon 2006/2007 zarówno dla Piszczka, jak i dla całej drużyny „Miedziowych” był bardzo udany – Zagłębie Lubin po raz drugi w swojej historii zdobyło mistrzostwo Polski, a Łukasz Piszczek z jedenastoma trafieniami został trzecim strzelcem sezonu. Po zakończeniu sezonu Piszczek powrócił do Herthy.\n",
      "True answer: tak\n",
      "Predicted answer: tak\n",
      "    Index: 1746\n",
      "Question: Z kim, za namową Sereny, zaczyna sypiać Freda?\n",
      "Context: Kierowca Komendanta, który mieszka nad garażem. Po sugestii ze strony Sereny Joy, Freda rozpoczyna z nim stosunki seksualne, aby zwiększyć swoje szanse na zajście w ciążę i ocalenie się przed wysłaniem do osławionej Kolonii. Z czasem Freda zaczyna coś czuć do Nicka, opowiadając mu nawet o swoim życiu przed powstaniem Gileadu. Nick jest niejednoznacznym bohaterem, a Freda do końca nie wie, czy jest on po stronie rządu, czy też ruchu oporu. Pod koniec opowieści Nick ujawnia jednak swoją prawdziwą przynależność polityczną i organizuje Fredzie ucieczkę.\n",
      "True answer: z kierowcą Komendanta\n",
      "Predicted answer: z Nickiem\n",
      "    Index: 1324\n",
      "Question: Dlaczego Niemcy wyruszyli w morze 24 kwietnia 1916 roku?\n",
      "Context: Kolejny raz siły niemieckie wyszły w morze rankiem 24 kwietnia 1916 roku. Celem akcji było zbombardowanie angielskich miast: Lowestoft i Great Yarmouth. 1. Grupą Rozpoznawczą dowodził, w zastępstwie chorego admirała Hippera, wiceadmirał Friedrich Bödicker. Jego okręt flagowy, „Seydlitz”, wszedł w trakcie rejsu na minę i został uszkodzony, w wyniku czego admirał Bödicker przeniósł się ze swoim sztabem na „Lützowa”. W ślad za krążownikami liniowymi podążały główne siły Hochseeflotte pod dowództwem admirała Reinharda Scheera, stanowiące daleką osłonę na wypadek kontrakcji okrętów brytyjskiej Grand Fleet.\n",
      "True answer: aby zbombardować angielskie miasta\n",
      "Predicted answer: celem akcji było zbombardowanie angielskich miast: Lowestoft i Great Yarmouth\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    show_question(validation_data, qa, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the performance on the validation dataset reflects the performance on your test set?\n",
    "\n",
    "The performance on validation dataset is better than the performance for test dataset, especially in case of exact match score. This is due to the fact that test data are single domain specific.\n",
    "\n",
    "## What are the outcomes of the model on your test questions? Are they satisfying? If not, what might be the reason for that?\n",
    "\n",
    "Most of answers are correct for selected questions. In case of question about Łukasz Piszczek's Polish League championship, in context there is information that his club achieved this and model probably did not deduct it means that their player also achieved this. \n",
    "\n",
    "## Why extractive question answering is not well suited for inflectional languages?\n",
    "\n",
    "Extractive question answering struggles with inflectional languages due to the complexity of word forms and grammatical variations, making direct keyword matching less reliable. The multitude of word forms and varied grammatical structures in inflectional languages pose challenges for accurate question-to-text alignment in extractive systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
